{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "import soft_kmeans_alg \n",
    "import new_utils \n",
    "import json \n",
    "import numpy as np \n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not available: 14\n"
     ]
    }
   ],
   "source": [
    "j_values = [50, 200, 500]\n",
    "r_values = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "m_values = range(50)  # From 0 to 49 (inclusive)\n",
    "temp_json_results_dir = 'temp_json_results'\n",
    "not_available_fnames_file = 'results/not_available_fnames.txt'\n",
    "\n",
    "dic = {}\n",
    "dic['param'] = {\n",
    "    \"num_of_datasets_per_combination\": 50,\n",
    "    \"n_iter\": 5000,\n",
    "    \"n_biomarkers\": 10\n",
    "}\n",
    "not_available_fnames = []\n",
    "not_available_count = 0\n",
    "for j in j_values:\n",
    "    for r in r_values:\n",
    "        combstr = f\"{int(j*r)}|{j}\"\n",
    "        if combstr not in dic:\n",
    "            dic[combstr] = []\n",
    "        for m in m_values:\n",
    "            try:\n",
    "                with open(f\"{temp_json_results_dir}/temp_results_{j}_{r}_{m}.json\") as f:\n",
    "                    d = json.load(f)\n",
    "                tau = list(d.values())[0][0]\n",
    "                dic[combstr].append(tau)\n",
    "            except:\n",
    "                not_available_count += 1\n",
    "                fname = f\"{j} {r} {m}\"\n",
    "                not_available_fnames.append(fname)\n",
    "                dic[combstr].append(np.nan)\n",
    "\n",
    "print(f\"not available: {not_available_count}\")\n",
    "with open('results/results.json', \"w\") as file:\n",
    "        json.dump(dic, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(not_available_fnames_file, \"w\") as f:\n",
    "    for item in not_available_fnames:\n",
    "        f.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['500 0.1 5',\n",
       " '500 0.1 17',\n",
       " '500 0.1 25',\n",
       " '500 0.1 26',\n",
       " '500 0.1 31',\n",
       " '500 0.1 32',\n",
       " '500 0.1 33',\n",
       " '500 0.1 37',\n",
       " '500 0.1 38',\n",
       " '500 0.1 43',\n",
       " '500 0.1 44',\n",
       " '500 0.1 49',\n",
       " '500 0.25 0',\n",
       " '500 0.25 4']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(not_available_fnames_file, 'r') as f: \n",
    "    loaded_list = [l.strip() for l in f]\n",
    "loaded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = [50, 200, 500]\n",
    "rs = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "num_of_datasets_per_combination = 50\n",
    "alist = [\n",
    "        f\"{int(j*r)}|{j}_{m}\"\n",
    "        for j in js\n",
    "        for r in rs\n",
    "        for m in range(num_of_datasets_per_combination)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'5|50': [-0.19999999999999998]}\n",
      "-0.19999999999999998\n"
     ]
    }
   ],
   "source": [
    "# with open('temp_json_results/temp_results_50_0.1_0.json') as f:\n",
    "#     d = json.load(f)\n",
    "#     print(d)\n",
    "# print(list(d.values())[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the ranges\n",
    "\n",
    "\n",
    "# # Generate all combinations\n",
    "# combinations = [(j, r, m) for j in j_values for r in r_values for m in m_values]\n",
    "\n",
    "# # Print the result\n",
    "# for combo in combinations:\n",
    "#     print(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_shuffle = 2\n",
    "# iterations = 100\n",
    "# burn_in = 10\n",
    "# thining = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"data/synthetic/5|50_2.csv\")\n",
    "# data.head()\n",
    "# n_biomarkers = len(data.biomarker.unique())\n",
    "# # biomarker_df = data[data['biomarker'] == \"HIP-FCI (1)\"].reset_index(drop=True)\n",
    "# # biomarker_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_current_accepted_order_dicts = soft_kmeans_alg.metropolis_hastings_soft_kmeans(\n",
    "#     data,\n",
    "#     iterations,\n",
    "#     n_shuffle,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_utils.save_heatmap(all_current_accepted_order_dicts,\n",
    "#                        burn_in, thining, folder_name='img',\n",
    "#                        file_name='test_heatmap', title='heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_likely_order_dic = new_utils.obtain_most_likely_order_dic(\n",
    "#     all_current_accepted_order_dicts, burn_in, thining)\n",
    "# most_likely_order = list(most_likely_order_dic.values())\n",
    "# tau, p_value = kendalltau(most_likely_order, range(1, n_biomarkers + 1))\n",
    "# dic = {}\n",
    "# dic['5|50'] = []\n",
    "# dic['5|50'].append(tau)\n",
    "# # write the JSON to a file\n",
    "# with open(\"results.json\", \"w\") as file:\n",
    "#     json.dump(dic, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_utils.get_theta_phi_estimates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biomarker_df.measurement.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reshape to satisfy sklearn requirements\n",
    "# measurements = np.array(biomarker_df['measurement']).reshape(-1, 1)\n",
    "\n",
    "# # dataframe for non-diseased participants\n",
    "# healthy_df = biomarker_df[biomarker_df['diseased'] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans_setup = KMeans(2, random_state=0, n_init=\"auto\")\n",
    "# hierarchical_clustering_setup = AgglomerativeClustering(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering_result_kmeans = kmeans_setup.fit(measurements)\n",
    "# clustering_result_kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering_result_kmeans.predict(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_mean, theta_std, phi_mean, phi_std = utils.compute_theta_phi_for_biomarker(\n",
    "#     data, \"HIP-FCI (1)\", clustering_setup = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_mean, theta_std, phi_mean, phi_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biomarkers = data.biomarker.unique()\n",
    "# utils.get_theta_phi_estimates(data, biomarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
